{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83932906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Base path configuration\n",
    "BASE_PATH = Path(r\"C:\\Code\\KHDL_Lab02_v2\")\n",
    "DATA_FOLDER = \"23120260\"  # Change this to your student ID folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45fd0a",
   "metadata": {},
   "source": [
    "## Manual Ground Truth Labels\n",
    "\n",
    "Format: `\"publication_id\": {\"bibitem_key\": \"arxiv_id\", ...}`\n",
    "\n",
    "Each entry maps a citation key (from the paper's bibliography) to the corresponding arXiv paper ID (from references.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MANUAL GROUND TRUTH LABELS - Edit these dictionaries to add your labels\n",
    "# ============================================================================\n",
    "\n",
    "# Publication partition assignments (requirement: 1 manual test, 1 manual valid, rest train)\n",
    "MANUAL_PARTITIONS = {\n",
    "    \"2411-00222\": \"test\",   # Manual test set\n",
    "    \"2411-00223\": \"valid\",  # Manual validation set\n",
    "    \"2411-00225\": \"train\",\n",
    "    \"2411-00226\": \"train\",\n",
    "    \"2411-00227\": \"train\",\n",
    "}\n",
    "\n",
    "MANUAL_LABELS = {\n",
    "    # Publication 2411-00222: Protecting Feed-Forward Networks from Adversarial Attacks\n",
    "    \"2411-00222\": {\n",
    "        \"kumar2019failure\": \"1911-11034\",       # Failure Modes in Machine Learning Systems\n",
    "        \"szegedy2013intriguing\": \"1312-6199\",   # Intriguing properties of neural networks\n",
    "        \"carlini2017adversarial\": \"1705-07263\", # Adversarial examples are not easily detected\n",
    "        \"goodfellow2014explaining\": \"1412-6572\", # Explaining and harnessing adversarial examples\n",
    "        \"kurakin2018adversarial\": \"1607-02533\", # Adversarial examples in the physical world\n",
    "        \"madry2017towards\": \"1706-06083\",       # Towards deep learning models resistant to adversarial attacks\n",
    "        \"papernot2016limitations\": \"1511-07528\", # The limitations of deep learning in adversarial settings\n",
    "        \"moosavi2016deepfool\": \"1511-04599\",    # DeepFool: a simple and accurate method to fool DNNs\n",
    "        \"moosavi2017universal\": \"1610-08401\",   # Universal adversarial perturbations\n",
    "        \"xiao2018generating\": \"1801-02610\",     # Generating adversarial examples with adversarial networks\n",
    "        \"zhang2019theoretically\": \"1901-08573\", # Theoretically principled trade-off robustness/accuracy\n",
    "        \"papernot2016distillation\": \"1511-04508\", # Distillation as a defense to adversarial perturbations\n",
    "        \"Millidge2020\": \"2006-04182\",           # Predictive Coding Approximates Backprop\n",
    "        \"nokland2016direct\": \"1609-01596\",      # Direct Feedback Alignment Provides Learning in DNNs\n",
    "        \"liao2016important\": \"1510-05067\",      # How important is weight symmetry in backpropagation\n",
    "    },\n",
    "    \n",
    "    # Publication 2411-00223: Graph-based control (Social robot navigation)\n",
    "    \"2411-00223\": {\n",
    "        \"mavrogiannis2023core\": \"2103-05668\",   # Core Challenges of Social Robot Navigation: A Survey\n",
    "        \"sebastian2023learning\": \"2307-04374\",  # Learning to Identify Graphs from Node Trajectories\n",
    "        \"mateos2019connecting\": \"1810-13066\",   # Connecting the Dots: Identifying Network Structure\n",
    "        \"gama2021graph\": \"2003-10280\",          # Graph Neural Networks for Decentralized Controllers\n",
    "        \"mohamed2020social\": \"2002-11927\",      # Social-STGCNN: Social Spatio-Temporal Graph CNN\n",
    "    },\n",
    "    \n",
    "    # Publication 2411-00225: FashionVDM Video Diffusion Model\n",
    "    \"2411-00225\": {\n",
    "        \"kim2023stableviton\": \"2312-01725\",     # StableVITON: Learning Semantic Correspondence\n",
    "        \"zhang2023warpdiffusion\": \"2312-03667\", # WarpDiffusion for High-Fidelity Virtual Try-on\n",
    "        \"cui2023streettry\": \"2311-16094\",       # Street TryOn: Learning In-the-Wild Virtual Try-On\n",
    "        \"girdhar2023emuvideo\": \"2311-10709\",    # Emu Video: Factorizing Text-to-Video Generation\n",
    "        \"chen2023seine\": \"2310-20700\",          # SEINE: Short-to-Long Video Diffusion Model\n",
    "        \"guo2023animatediff\": \"2307-04725\",     # AnimateDiff: Animate Your Personalized T2I\n",
    "        \"zhu2023tryondiffusion\": \"2306-08276\",  # TryOnDiffusion: A Tale of Two UNets\n",
    "        \"wang2023genlvideo\": \"2305-18264\",      # Gen-L-Video: Multi-Text to Long Video Generation\n",
    "    },\n",
    "    \n",
    "    # Publication 2411-00226: Equivariant geometry of low-dimensional quadrics\n",
    "    \"2411-00226\": {\n",
    "        \"hassett2020symbols\": \"2010-08902\",     # Symbols and equivariant birational geometry\n",
    "        \"kresch2020equivariant\": \"2007-12538\",  # Equivariant birational types and Burnside volume\n",
    "        \"hassett2022torsors\": \"2204-03106\",     # Torsors and stable equivariant birational geometry\n",
    "        \"kollar2022automorphisms\": \"2212-03772\", # Automorphisms and twisted forms of invariants\n",
    "        \"tschinkel2023equivariant\": \"2302-02296\", # Equivariant birational geometry of linear actions\n",
    "        \"bohning2023equivariant\": \"2303-17678\", # Equivariant birational geometry of cubic fourfolds\n",
    "        \"duncan2011versality\": \"1109-6093\",     # Versality of algebraic group actions\n",
    "        \"dolgachev2006finite\": \"math-0610595\",  # Finite subgroups of plane Cremona group\n",
    "        \"lemire2005cayley\": \"math-0409004\",     # Cayley groups\n",
    "        \"colliot1987rationality\": \"math-0507154\", # The rationality problem for fields of invariants\n",
    "    },\n",
    "    \n",
    "    # Publication 2411-00227: Taut foliations and flows\n",
    "    \"2411-00227\": {\n",
    "        \"calegari.ProblemsFoliationsLaminations\": \"math-0209081\",  # Problems in foliations and laminations\n",
    "        \"calegari.GeometryRcoveredFoliations\": \"math-9903173\",     # The Geometry of R-covered foliations\n",
    "        \"thurston.ThreemanifoldsFoliationsCircles\": \"math-9712268\", # Three-manifolds, Foliations, Circles\n",
    "        \"dunfield.FloerHomologyGroup\": \"1904-04628\",               # Floer homology, group orderability\n",
    "        \"krishna.TautFoliationsBraid\": \"1809-03959\",               # Taut Foliations, Positive 3-Braids\n",
    "        \"krishna.TautFoliationsPositive\": \"2312-00196\",            # Taut foliations, braid positivity\n",
    "        \"li.roberts.TautFoliationsKnot\": \"1211-3066\",              # Taut foliations in knot complements\n",
    "        \"landry.VeeringTriangulationsThurston\": \"2006-16328\",      # Veering triangulations and Thurston norm\n",
    "        \"landry.tsang.EndperiodicMapsSplitting\": \"2304-14481\",     # Endperiodic maps, splitting sequences\n",
    "        \"landry.minsky.ea.TransverseSurfacesPseudoAnosov\": \"2406-17717\", # Transverse surfaces\n",
    "        \"landry.minsky.ea.FlowsGrowthRates\": \"2107-04066\",         # Flows, growth rates, veering polynomial\n",
    "        \"massoni.TautFoliationsContact\": \"2405-15635\",             # Taut foliations and contact pairs\n",
    "\n",
    "        \"zhao.CoorientableTautFoliations\": \"2310-01368\",           # Co-orientable taut foliations}\n",
    "\n",
    "        \"zung.PseudoAnosovRepresentativesStable\": \"2410-02186\",    # Pseudo-Anosov representatives    # },\n",
    "\n",
    "    },    #     \"citation_key\": \"arxiv_id\",\n",
    "\n",
    "        # \"2411-00228\": {\n",
    "    # Add more publications below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ecde7",
   "metadata": {},
   "source": [
    "## Write Labels to pred.json Files\n",
    "\n",
    "This cell writes the manual labels to each publication's `pred.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f0ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_references(pub_path: Path) -> dict:\n",
    "    \"\"\"Load references.json to get candidate arXiv IDs.\"\"\"\n",
    "    ref_file = pub_path / \"references.json\"\n",
    "    if ref_file.exists():\n",
    "        with open(ref_file, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def get_all_bibitem_keys(pub_path: Path) -> list:\n",
    "    \"\"\"Extract all bibitem keys from tex files.\"\"\"\n",
    "    import re\n",
    "    keys = []\n",
    "    tex_folder = pub_path / \"tex\"\n",
    "    \n",
    "    if not tex_folder.exists():\n",
    "        return keys\n",
    "    \n",
    "    for tex_file in tex_folder.rglob(\"*.tex\"):\n",
    "        try:\n",
    "            with open(tex_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "                # Find \\bibitem{key}\n",
    "                bibitem_matches = re.findall(r'\\\\bibitem(?:\\[.*?\\])?\\{([^}]+)\\}', content)\n",
    "                keys.extend(bibitem_matches)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    return list(set(keys))\n",
    "\n",
    "\n",
    "def write_pred_json(pub_path: Path, groundtruth: dict, partition: str = \"train\"):\n",
    "    \"\"\"Write pred.json file with groundtruth labels.\"\"\"\n",
    "    # Create prediction dict with empty arrays for each labeled item\n",
    "    prediction = {key: [] for key in groundtruth.keys()}\n",
    "    \n",
    "    pred_data = {\n",
    "        \"partition\": partition,\n",
    "        \"groundtruth\": groundtruth,\n",
    "        \"prediction\": prediction\n",
    "    }\n",
    "    \n",
    "    pred_file = pub_path / \"pred.json\"\n",
    "    with open(pred_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(pred_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return pred_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5b9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing manual labels...\n",
      "============================================================\n",
      "\n",
      "âœ… Successfully written:\n",
      "  2411-00222: 15 labels -> C:\\Code\\KHDL_Lab02_v2\\23120260\\2411-00222\\pred.json\n",
      "  2411-00223: 5 labels -> C:\\Code\\KHDL_Lab02_v2\\23120260\\2411-00223\\pred.json\n",
      "  2411-00225: 8 labels -> C:\\Code\\KHDL_Lab02_v2\\23120260\\2411-00225\\pred.json\n",
      "  2411-00226: 10 labels -> C:\\Code\\KHDL_Lab02_v2\\23120260\\2411-00226\\pred.json\n",
      "  2411-00227: 14 labels -> C:\\Code\\KHDL_Lab02_v2\\23120260\\2411-00227\\pred.json\n",
      "\n",
      "============================================================\n",
      "Summary: 5 success, 0 failed, 0 skipped\n"
     ]
    }
   ],
   "source": [
    "def process_all_labels():\n",
    "    \"\"\"Process all manual labels and write to pred.json files.\"\"\"\n",
    "    data_path = BASE_PATH / DATA_FOLDER\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        print(f\"Error: Data folder not found: {data_path}\")\n",
    "        return\n",
    "    \n",
    "    results = {\n",
    "        \"success\": [],\n",
    "        \"failed\": [],\n",
    "        \"skipped\": []\n",
    "    }\n",
    "    \n",
    "    for pub_id, labels in MANUAL_LABELS.items():\n",
    "        pub_path = data_path / pub_id\n",
    "        \n",
    "        if not pub_path.exists():\n",
    "            results[\"skipped\"].append((pub_id, \"Publication folder not found\"))\n",
    "            continue\n",
    "        \n",
    "        if not labels:\n",
    "            results[\"skipped\"].append((pub_id, \"No labels defined\"))\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load references to validate arXiv IDs\n",
    "            references = load_references(pub_path)\n",
    "            \n",
    "            # Validate labels against references\n",
    "            valid_labels = {}\n",
    "            invalid_labels = []\n",
    "            \n",
    "            for bib_key, arxiv_id in labels.items():\n",
    "                if arxiv_id in references:\n",
    "                    valid_labels[bib_key] = arxiv_id\n",
    "                else:\n",
    "                    invalid_labels.append((bib_key, arxiv_id))\n",
    "            \n",
    "            if invalid_labels:\n",
    "                print(f\"Warning [{pub_id}]: Invalid arXiv IDs not in references.json:\")\n",
    "                for bib_key, arxiv_id in invalid_labels:\n",
    "                    print(f\"  - {bib_key} -> {arxiv_id}\")\n",
    "            \n",
    "            if valid_labels:\n",
    "                # Get partition from MANUAL_PARTITIONS (default to train)\n",
    "                partition = MANUAL_PARTITIONS.get(pub_id, \"train\")\n",
    "                pred_file = write_pred_json(pub_path, valid_labels, partition=partition)\n",
    "                results[\"success\"].append((pub_id, len(valid_labels), str(pred_file), partition))\n",
    "            else:\n",
    "                results[\"failed\"].append((pub_id, \"No valid labels after validation\"))\n",
    "                \n",
    "        except Exception as e:\n",
    "            results[\"failed\"].append((pub_id, str(e)))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run the labeling process\n",
    "print(\"Processing manual labels...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = process_all_labels()\n",
    "\n",
    "print(\"\\nâœ… Successfully written:\")\n",
    "for pub_id, count, path in results[\"success\"]:\n",
    "    print(f\"  {pub_id}: {count} labels -> {path}\")\n",
    "\n",
    "if results[\"failed\"]:\n",
    "    print(\"\\nâŒ Failed:\")\n",
    "    for pub_id, error in results[\"failed\"]:\n",
    "        print(f\"  {pub_id}: {error}\")\n",
    "\n",
    "if results[\"skipped\"]:\n",
    "    print(\"\\nâ­ï¸ Skipped:\")\n",
    "    for pub_id, reason in results[\"skipped\"]:\n",
    "        print(f\"  {pub_id}: {reason}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)print(f\"Summary: {len(results['success'])} success, {len(results['failed'])} failed, {len(results['skipped'])} skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d55213",
   "metadata": {},
   "source": [
    "## Verify Written Labels\n",
    "\n",
    "Check what was written to verify correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bb3ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying written labels:\n",
      "============================================================\n",
      "\n",
      "ðŸ“„ 2411-00222/pred.json:\n",
      "   Partition: train\n",
      "   Ground Truth Labels (15)::\n",
      "     kumar2019failure -> 1911-11034\n",
      "     szegedy2013intriguing -> 1312-6199\n",
      "     carlini2017adversarial -> 1705-07263\n",
      "     goodfellow2014explaining -> 1412-6572\n",
      "     kurakin2018adversarial -> 1607-02533\n",
      "     madry2017towards -> 1706-06083\n",
      "     papernot2016limitations -> 1511-07528\n",
      "     moosavi2016deepfool -> 1511-04599\n",
      "     moosavi2017universal -> 1610-08401\n",
      "     xiao2018generating -> 1801-02610\n",
      "     zhang2019theoretically -> 1901-08573\n",
      "     papernot2016distillation -> 1511-04508\n",
      "     Millidge2020 -> 2006-04182\n",
      "     nokland2016direct -> 1609-01596\n",
      "     liao2016important -> 1510-05067\n",
      "\n",
      "ðŸ“„ 2411-00223/pred.json:\n",
      "   Partition: train\n",
      "   Ground Truth Labels (5)::\n",
      "     mavrogiannis2023core -> 2103-05668\n",
      "     sebastian2023learning -> 2307-04374\n",
      "     mateos2019connecting -> 1810-13066\n",
      "     gama2021graph -> 2003-10280\n",
      "     mohamed2020social -> 2002-11927\n",
      "\n",
      "ðŸ“„ 2411-00225/pred.json:\n",
      "   Partition: train\n",
      "   Ground Truth Labels (8)::\n",
      "     kim2023stableviton -> 2312-01725\n",
      "     zhang2023warpdiffusion -> 2312-03667\n",
      "     cui2023streettry -> 2311-16094\n",
      "     girdhar2023emuvideo -> 2311-10709\n",
      "     chen2023seine -> 2310-20700\n",
      "     guo2023animatediff -> 2307-04725\n",
      "     zhu2023tryondiffusion -> 2306-08276\n",
      "     wang2023genlvideo -> 2305-18264\n",
      "\n",
      "ðŸ“„ 2411-00226/pred.json:\n",
      "   Partition: train\n",
      "   Ground Truth Labels (10)::\n",
      "     hassett2020symbols -> 2010-08902\n",
      "     kresch2020equivariant -> 2007-12538\n",
      "     hassett2022torsors -> 2204-03106\n",
      "     kollar2022automorphisms -> 2212-03772\n",
      "     tschinkel2023equivariant -> 2302-02296\n",
      "     bohning2023equivariant -> 2303-17678\n",
      "     duncan2011versality -> 1109-6093\n",
      "     dolgachev2006finite -> math-0610595\n",
      "     lemire2005cayley -> math-0409004\n",
      "     colliot1987rationality -> math-0507154\n",
      "\n",
      "ðŸ“„ 2411-00227/pred.json:\n",
      "   Partition: train\n",
      "   Ground Truth Labels (14)::\n",
      "     calegari.ProblemsFoliationsLaminations -> math-0209081\n",
      "     calegari.GeometryRcoveredFoliations -> math-9903173\n",
      "     thurston.ThreemanifoldsFoliationsCircles -> math-9712268\n",
      "     dunfield.FloerHomologyGroup -> 1904-04628\n",
      "     krishna.TautFoliationsBraid -> 1809-03959\n",
      "     krishna.TautFoliationsPositive -> 2312-00196\n",
      "     li.roberts.TautFoliationsKnot -> 1211-3066\n",
      "     landry.VeeringTriangulationsThurston -> 2006-16328\n",
      "     landry.tsang.EndperiodicMapsSplitting -> 2304-14481\n",
      "     landry.minsky.ea.TransverseSurfacesPseudoAnosov -> 2406-17717\n",
      "     landry.minsky.ea.FlowsGrowthRates -> 2107-04066\n",
      "     massoni.TautFoliationsContact -> 2405-15635\n",
      "     zhao.CoorientableTautFoliations -> 2310-01368\n",
      "     zung.PseudoAnosovRepresentativesStable -> 2410-02186\n"
     ]
    }
   ],
   "source": [
    "def verify_labels():\n",
    "    \"\"\"Read back and display all written labels.\"\"\"\n",
    "    data_path = BASE_PATH / DATA_FOLDER\n",
    "    \n",
    "    print(\"Verifying written labels:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for pub_id in MANUAL_LABELS.keys():\n",
    "        pub_path = data_path / pub_id\n",
    "        pred_file = pub_path / \"pred.json\"\n",
    "        \n",
    "        if pred_file.exists():\n",
    "            with open(pred_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            print(f\"\\nðŸ“„ {pub_id}/pred.json:\")\n",
    "            print(f\"   Partition: {data.get('partition', 'N/A')}\")\n",
    "            print(f\"   Ground Truth Labels ({len(data.get('groundtruth', {}))})::\")\n",
    "            \n",
    "            for bib_key, arxiv_id in data.get('groundtruth', {}).items():\n",
    "                print(f\"     {bib_key} -> {arxiv_id}\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ {pub_id}/pred.json: Not found\")\n",
    "\n",
    "verify_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa9ddfd",
   "metadata": {},
   "source": [
    "## Helper: Explore Publication for Labeling\n",
    "\n",
    "Use this cell to explore a specific publication and identify matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_publication(pub_id: str):\n",
    "    \"\"\"Explore a publication to help with manual labeling.\"\"\"\n",
    "    data_path = BASE_PATH / DATA_FOLDER / pub_id\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        print(f\"Publication not found: {pub_id}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Exploring: {pub_id}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load references\n",
    "    references = load_references(data_path)\n",
    "    print(f\"\\nðŸ“š Candidate arXiv Papers ({len(references)})::\")\n",
    "    for arxiv_id, info in list(references.items())[:20]:  # Show first 20\n",
    "        title = info.get('paper_title', 'N/A')[:60]\n",
    "        authors = ', '.join(info.get('authors', [])[:3])\n",
    "        print(f\"  {arxiv_id}: {title}...\")\n",
    "        print(f\"           by {authors}\")\n",
    "    \n",
    "    if len(references) > 20:\n",
    "        print(f\"  ... and {len(references) - 20} more\")\n",
    "    \n",
    "    # Get bibitems\n",
    "    bibitem_keys = get_all_bibitem_keys(data_path)\n",
    "    print(f\"\\nðŸ“ BibItem Keys Found ({len(bibitem_keys)})::\")\n",
    "    for key in bibitem_keys[:30]:  # Show first 30\n",
    "        print(f\"  - {key}\")\n",
    "    \n",
    "    if len(bibitem_keys) > 30:\n",
    "        print(f\"  ... and {len(bibitem_keys) - 30} more\")\n",
    "\n",
    "\n",
    "# Example: explore a publication\n",
    "# explore_publication(\"2411-00228\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e4d2f",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a0ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Labeling Statistics:\n",
      "  Total publications labeled: 5\n",
      "  Total label pairs: 52\n",
      "  Average labels per publication: 10.4\n",
      "\n",
      "Per publication:\n",
      "  2411-00222: 15 labels\n",
      "  2411-00223: 5 labels\n",
      "  2411-00225: 8 labels\n",
      "  2411-00226: 10 labels\n",
      "  2411-00227: 14 labels\n"
     ]
    }
   ],
   "source": [
    "# Count total labels\n",
    "total_pubs = len(MANUAL_LABELS)\n",
    "total_labels = sum(len(labels) for labels in MANUAL_LABELS.values())\n",
    "\n",
    "print(f\"Manual Labeling Statistics:\")\n",
    "print(f\"  Total publications labeled: {total_pubs}\")\n",
    "print(f\"  Total label pairs: {total_labels}\")\n",
    "print(f\"  Average labels per publication: {total_labels/total_pubs:.1f}\")\n",
    "\n",
    "print(\"\\nPer publication:\")\n",
    "for pub_id, labels in MANUAL_LABELS.items():\n",
    "    print(f\"  {pub_id}: {len(labels)} labels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
