{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4952194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from matching import BibEntry, RefEntry, TextCleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce79fd1",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dada037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 893 publications\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = Path(\"../../output\")\n",
    "\n",
    "with open(OUTPUT_DIR / 'extracted_data.json', 'r', encoding='utf-8') as f:\n",
    "    all_data = json.load(f)\n",
    "print(f\"Loaded {len(all_data)} publications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb84acf",
   "metadata": {},
   "source": [
    "## 2. Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bab62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"Feature extraction for reference matching (ranking problem)\"\"\"\n",
    "    \n",
    "    FEATURE_NAMES = [\n",
    "        'title_jaccard', 'title_overlap', 'title_edit_dist',\n",
    "        'author_overlap', 'first_author_match', 'year_match', 'year_diff',\n",
    "        'arxiv_match', 'arxiv_in_content', 'num_matching_authors', \n",
    "        'title_len_ratio', 'combined_score'\n",
    "    ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def jaccard_similarity(set1: Set[str], set2: Set[str]) -> float:\n",
    "        if not set1 or not set2:\n",
    "            return 0.0\n",
    "        return len(set1 & set2) / len(set1 | set2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def token_overlap_ratio(tokens1: List[str], tokens2: List[str]) -> float:\n",
    "        if not tokens1 or not tokens2:\n",
    "            return 0.0\n",
    "        set1, set2 = set(tokens1), set(tokens2)\n",
    "        return len(set1 & set2) / min(len(set1), len(set2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def levenshtein_distance(s1: str, s2: str) -> int:\n",
    "        if len(s1) < len(s2):\n",
    "            return FeatureExtractor.levenshtein_distance(s2, s1)\n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "        prev_row = range(len(s2) + 1)\n",
    "        for i, c1 in enumerate(s1):\n",
    "            curr_row = [i + 1]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                curr_row.append(min(prev_row[j + 1] + 1, curr_row[j] + 1, prev_row[j] + (c1 != c2)))\n",
    "            prev_row = curr_row\n",
    "        return prev_row[-1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_features(bib: Dict, ref: Dict) -> Dict[str, float]:\n",
    "        features = {}\n",
    "        \n",
    "        # Title features\n",
    "        bib_title = TextCleaner.clean_title(bib.get('title', ''))\n",
    "        ref_title = TextCleaner.clean_title(ref.get('title', ''))\n",
    "        bib_tokens = TextCleaner.tokenize(bib_title)\n",
    "        ref_tokens = TextCleaner.tokenize(ref_title)\n",
    "        \n",
    "        features['title_jaccard'] = FeatureExtractor.jaccard_similarity(set(bib_tokens), set(ref_tokens))\n",
    "        features['title_overlap'] = FeatureExtractor.token_overlap_ratio(bib_tokens, ref_tokens)\n",
    "        \n",
    "        if bib_title and ref_title:\n",
    "            dist = FeatureExtractor.levenshtein_distance(bib_title, ref_title)\n",
    "            features['title_edit_dist'] = 1.0 - dist / max(len(bib_title), len(ref_title))\n",
    "        else:\n",
    "            features['title_edit_dist'] = 0.0\n",
    "        \n",
    "        # Author features\n",
    "        bib_authors = TextCleaner.extract_author_last_names(bib.get('authors', [])[:50])\n",
    "        ref_authors = TextCleaner.extract_author_last_names(ref.get('authors', [])[:50])\n",
    "        features['author_overlap'] = FeatureExtractor.token_overlap_ratio(bib_authors, ref_authors)\n",
    "        features['first_author_match'] = 1.0 if bib_authors and ref_authors and bib_authors[0] == ref_authors[0] else 0.0\n",
    "        features['num_matching_authors'] = min(len(set(bib_authors) & set(ref_authors)), 20)\n",
    "        \n",
    "        # Year features\n",
    "        bib_year = bib.get('year') or TextCleaner.extract_year(bib.get('raw_content', ''))\n",
    "        ref_year = ref.get('year', '')\n",
    "        features['year_match'] = 1.0 if bib_year and ref_year and bib_year == ref_year else 0.0\n",
    "        try:\n",
    "            features['year_diff'] = min(abs(int(bib_year) - int(ref_year)), 50) if bib_year and ref_year else 10\n",
    "        except ValueError:\n",
    "            features['year_diff'] = 10\n",
    "        \n",
    "        # ArXiv features\n",
    "        bib_arxiv = (bib.get('arxiv_id') or '').replace('.', '-')\n",
    "        ref_arxiv = (ref.get('arxiv_id') or '').replace('.', '-')\n",
    "        features['arxiv_match'] = 1.0 if bib_arxiv and ref_arxiv and bib_arxiv == ref_arxiv else 0.0\n",
    "        features['arxiv_in_content'] = 1.0 if ref_arxiv.replace('-', '.') in bib.get('raw_content', '') else 0.0\n",
    "        \n",
    "        # Title length ratio\n",
    "        len_ratio = len(bib_title) / len(ref_title) if ref_title else 0\n",
    "        features['title_len_ratio'] = min(len_ratio, 1/len_ratio) if len_ratio > 0 else 0\n",
    "        \n",
    "        # Combined score\n",
    "        features['combined_score'] = (0.4 * features['title_jaccard'] + 0.3 * features['author_overlap'] +\n",
    "                                      0.2 * features['year_match'] + 0.1 * features['first_author_match'])\n",
    "        return features\n",
    "    \n",
    "    @staticmethod\n",
    "    def features_to_vector(features: Dict[str, float]) -> np.ndarray:\n",
    "        return np.array([features.get(name, 0.0) for name in FeatureExtractor.FEATURE_NAMES])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5aa020",
   "metadata": {},
   "source": [
    "## 3. Test Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e7b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pub: 2411-00223, Bib: NonlinearConsensusDirected, Ref: 2307-04374\n",
      "  title_jaccard: 0.0000\n",
      "  title_overlap: 0.0000\n",
      "  title_edit_dist: 0.2027\n",
      "  author_overlap: 0.0000\n",
      "  first_author_match: 0.0000\n",
      "  num_matching_authors: 0.0000\n",
      "  year_match: 0.0000\n",
      "  year_diff: 12.0000\n",
      "  arxiv_match: 0.0000\n",
      "  arxiv_in_content: 0.0000\n",
      "  title_len_ratio: 0.3108\n",
      "  combined_score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Test feature extraction\n",
    "sample = all_data[0]\n",
    "bib, ref_key = sample['bibs'][0], list(sample['refs'].keys())[0]\n",
    "ref = sample['refs'][ref_key]\n",
    "features = FeatureExtractor.extract_features(bib, ref)\n",
    "\n",
    "print(f\"Pub: {sample['pub_id']}, Bib: {bib['key']}, Ref: {ref_key}\")\n",
    "for name, value in features.items():\n",
    "    print(f\"  {name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda72f27",
   "metadata": {},
   "source": [
    "## 4. Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0303189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_pairs(pub_data: Dict, max_candidates: int = 50) -> List[Dict]:\n",
    "    \"\"\"Generate candidate pairs for a publication\"\"\"\n",
    "    pairs = []\n",
    "    for bib in pub_data['bibs']:\n",
    "        candidates = []\n",
    "        for arxiv_id, ref in pub_data['refs'].items():\n",
    "            t1 = bib['title'].replace('\\n', ' ').strip()\n",
    "            t2 = ref['title'].replace('\\n', ' ').strip()\n",
    "            if abs(len(t1) - len(t2)) > 40:\n",
    "                continue\n",
    "            features = FeatureExtractor.extract_features(bib, ref)\n",
    "            candidates.append({'pub_id': pub_data['pub_id'], 'bib_key': bib['key'],\n",
    "                              'arxiv_id': arxiv_id, 'features': features})\n",
    "        candidates.sort(key=lambda x: x['features']['combined_score'], reverse=True)\n",
    "        pairs.extend(candidates[:max_candidates])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8dea897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 893 publications with 8 workers, batch size 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|██████████| 500/500 [01:01<00:00,  8.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1: 3150924 pairs, total: 3150924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|██████████| 393/393 [00:37<00:00, 10.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2: 2162392 pairs, total: 5313316\n",
      "\n",
      "Saved 5313316 pairs, feature shape: (5313316, 12)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "from feature_processor import generate_candidate_pairs_worker, FeatureProcessor\n",
    "\n",
    "num_workers = min(multiprocessing.cpu_count(), 8)\n",
    "batch_size = 500\n",
    "\n",
    "print(f\"Processing {len(all_data)} publications with {num_workers} workers, batch size {batch_size}\")\n",
    "\n",
    "all_metadata, all_features_list, total_pairs = [], [], 0\n",
    "\n",
    "for batch_idx in range((len(all_data) + batch_size - 1) // batch_size):\n",
    "    batch_data = all_data[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "    batch_pairs = []\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(generate_candidate_pairs_worker, pub) for pub in batch_data]\n",
    "        for future in tqdm(as_completed(futures), total=len(batch_data), desc=f\"Batch {batch_idx + 1}\"):\n",
    "            batch_pairs.extend(future.result())\n",
    "    \n",
    "    all_features_list.append(np.array([[p['features'].get(n, 0.0) for n in FeatureProcessor.FEATURE_NAMES] \n",
    "                                        for p in batch_pairs], dtype=np.float32))\n",
    "    all_metadata.extend([{'pub_id': p['pub_id'], 'bib_key': p['bib_key'], 'arxiv_id': p['arxiv_id'],\n",
    "                          'combined_score': p['features']['combined_score']} for p in batch_pairs])\n",
    "    total_pairs += len(batch_pairs)\n",
    "    print(f\"  Batch {batch_idx + 1}: {len(batch_pairs)} pairs, total: {total_pairs}\")\n",
    "\n",
    "# Save results\n",
    "X = np.vstack(all_features_list)\n",
    "np.save(OUTPUT_DIR / 'features.npy', X)\n",
    "with open(OUTPUT_DIR / 'pair_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved {X.shape[0]} pairs, feature shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f245ced",
   "metadata": {},
   "source": [
    "## 5. Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319ab6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Statistics:\n",
      "  title_jaccard         : mean=0.038, std=0.077, min=0.000, max=1.000\n",
      "  title_overlap         : mean=0.076, std=0.124, min=0.000, max=1.000\n",
      "  title_edit_dist       : mean=0.227, std=0.076, min=0.000, max=1.000\n",
      "  author_overlap        : mean=0.005, std=0.054, min=0.000, max=1.000\n",
      "  first_author_match    : mean=0.002, std=0.042, min=0.000, max=1.000\n",
      "  year_match            : mean=0.067, std=0.250, min=0.000, max=1.000\n",
      "  year_diff             : mean=9.110, std=9.558, min=0.000, max=50.000\n",
      "  arxiv_match           : mean=0.001, std=0.024, min=0.000, max=1.000\n",
      "  arxiv_in_content      : mean=0.001, std=0.032, min=0.000, max=1.000\n",
      "  num_matching_authors  : mean=0.016, std=0.208, min=0.000, max=20.000\n",
      "  title_len_ratio       : mean=0.710, std=0.207, min=0.000, max=1.000\n",
      "  combined_score        : mean=0.030, std=0.067, min=0.000, max=1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Statistics:\")\n",
    "for i, name in enumerate(FeatureExtractor.FEATURE_NAMES):\n",
    "    col = X[:, i]\n",
    "    print(f\"  {name:22s}: mean={col.mean():.3f}, std={col.std():.3f}, min={col.min():.3f}, max={col.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a6aba",
   "metadata": {},
   "source": [
    "---\n",
    "**Next:** `03_model_training.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
